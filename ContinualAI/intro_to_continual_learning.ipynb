{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "intro_to_continual_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fp9hbokQIxWW"
      },
      "source": [
        "# A Gentle Introduction to Continual Learning in PyTorch\n",
        "\n",
        "In this brief tutorial we will learn the basics of *Continual Learning* using *PyTorch 1.6* We will use the standard MNIST benchmark so that you can swiftly run this notebook from anywhere!\n",
        "\n",
        "This notebook was originally made by the *ContinualAI* community for their **[Colab](https://github.com/ContinualAI/colab)**, a repository meant for tutorials and demo running on Google Colaboratory. The notebook has been adapted for the scope of the **[1st AI for People Workshop](https://medium.com/ai-for-people/1st-ai-for-people-workshop-31782332aef6)**.\n",
        "\n",
        "We will start with learning over the standard *MNIST* benchmark, then we will move in the actual continual learning setting  with the *Permuted MNIST* benchmark. Let's have some fun! :-)\n",
        "\n",
        "\n",
        "---\n",
        "**Connecting a local runtime**\n",
        "\n",
        "In case resources are not enough for you (no GPU for example), you can always connect another [local runtime](https://research.google.com/colaboratory/local-runtimes.html) or to a [runtime on a Google Compute Engine instance](https://research.google.com/colaboratory/local-runtimes.html).\n",
        "\n",
        "This notebook has been designed to run fast enough on simple CPUs so you shouldn't find any trouble here, using a free *hosted account*.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Requisites to run it locally, outside colab (not recommended)**\n",
        "\n",
        "*   Python 3.x\n",
        "*   Jupyter\n",
        "*   PyTorch 0.4.0\n",
        "*   Numpy\n",
        "*   Matplolib\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z6RUp96FLuMd"
      },
      "source": [
        "## Google Colaboratory\n",
        "\n",
        "First of all, take a moment to look around and discover Google Colab if you haven't before! You can run the commands below to understand how much resources you're using and are still available. Then consider also that you can also connect your Google Drive for additional space or for easily loading your own files.\n",
        "\n",
        "You can always reset the entire VM with \"*Runtime > Reset all runtime*\" in case of difficulty. Make also sure you're using the GPU or TPU in the same  tab (\"*Runtime > Change runtime type*\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pPViRmMBqbJ2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "4d5c1668-bc69-4ef3-f1df-a72d4ddeaf48"
      },
      "source": [
        "!free -m\n",
        "!df -h\n",
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:          13021         632        3398           0        8989       12168\n",
            "Swap:             0           0           0\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay          69G   34G   32G  52% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
            "shm             5.8G     0  5.8G   0% /dev/shm\n",
            "tmpfs           6.4G   16K  6.4G   1% /var/colab\n",
            "/dev/sda1        75G   40G   36G  53% /opt/bin\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n",
            "Sat Aug  8 10:03:06 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jt_PxOYPmxp_"
      },
      "source": [
        "**Questions to explore:**\n",
        "\n",
        "*   How to connect your Google Drive with Google Colab?\n",
        "*   How to import a new notebook and save it to your GDrive?\n",
        "*   How to use files which are contained in your GDrive?\n",
        "\n",
        "Some tips here: https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eaSUr-B3NEZq"
      },
      "source": [
        "## Installing PyTorch 1.6.0\n",
        "\n",
        "Tensorflow is installed by default in Google Colab (guess why :P). If you want to use another DL toolkit you have to do it by yourself. Run the command below to install it. It should take less than a couple of minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5FwpAu9chwI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "b752cdf1-3bcb-4cc9-fcb4-0552e2c9b6b1"
      },
      "source": [
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.6.0+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.6.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (708.0MB)\n",
            "\u001b[K     |████████████████████████████████| 708.0MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.7.0+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.7.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 57.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (1.19.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0+cu101) (7.2.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0\n",
            "    Uninstalling torch-1.6.0:\n",
            "      Successfully uninstalled torch-1.6.0\n",
            "  Found existing installation: torchvision 0.7.0\n",
            "    Uninstalling torchvision-0.7.0:\n",
            "      Successfully uninstalled torchvision-0.7.0\n",
            "Successfully installed torch-1.6.0+cu101 torchvision-0.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i74kZQufNv5d"
      },
      "source": [
        "Ok, torch is installed and imported! Let' see if it can see the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hv7FUJ2Wrd_l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "68c288e7-4252-4bf8-fc71-01922748a486"
      },
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JuSqVkPnN7iT"
      },
      "source": [
        "That's great, let us import then a few libraries, which we'll be using during this tutorial!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w7AxhUWe68vT",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nGL7z5R2oxrX"
      },
      "source": [
        "**Questions to explore:**\n",
        "\n",
        "*   What's new in Pythorch 1.6?\n",
        "\n",
        "Some info here: https://github.com/pytorch/pytorch/releases\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rv89m9nBPXSh"
      },
      "source": [
        "## MNIST: Digits recognition with PyTorch \n",
        "\n",
        "All right, let's start then making sure we all know the basics! Let's recognize the ten handwritten digits learning from 60.000, 28x28 grayscale images.\n",
        "For simplicity let's import a loading script we have already developed inside the **Continual AI Colab** repository:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yKWbcnh474X3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "ea1ad1e3-3327-4e38-eedc-88b1e951921a"
      },
      "source": [
        "!git clone https://github.com/ContinualAI/colab.git continualai/colab"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'continualai/colab'...\n",
            "remote: Enumerating objects: 120, done.\u001b[K\n",
            "remote: Total 120 (delta 0), reused 0 (delta 0), pack-reused 120\u001b[K\n",
            "Receiving objects: 100% (120/120), 207.33 KiB | 283.00 KiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x3BFVukM_y8i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "60e48edb-614b-4afb-9176-43a2ae993ffe"
      },
      "source": [
        "from continualai.colab.scripts import mnist\n",
        "mnist.init()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train-images-idx3-ubyte.gz...\n",
            "Downloading t10k-images-idx3-ubyte.gz...\n",
            "Downloading train-labels-idx1-ubyte.gz...\n",
            "Downloading t10k-labels-idx1-ubyte.gz...\n",
            "Download complete.\n",
            "Save complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6jIk6-G6AhWi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "296a3383-2572-4d5c-a34b-d3baff4a8165"
      },
      "source": [
        "x_train, t_train, x_test, t_test = mnist.load()\n",
        "\n",
        "print(\"x_train dim and type: \", x_train.shape, x_train.dtype)\n",
        "print(\"t_train dim and type: \", t_train.shape, t_train.dtype)\n",
        "print(\"x_test dim and type: \", x_test.shape, x_test.dtype)\n",
        "print(\"t_test dim and type: \", t_test.shape, t_test.dtype)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train dim and type:  (60000, 1, 28, 28) float32\n",
            "t_train dim and type:  (60000,) uint8\n",
            "x_test dim and type:  (10000, 1, 28, 28) float32\n",
            "t_test dim and type:  (10000,) uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XEWG2PmbVvb7"
      },
      "source": [
        "Let's take a look at the actual images!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RyIuYAw8AuO6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "f2f88b5d-235b-434b-8588-5358a9f6492d"
      },
      "source": [
        "f, axarr = plt.subplots(2,2)\n",
        "axarr[0,0].imshow(x_train[1, 0], cmap=\"gray\")\n",
        "axarr[0,1].imshow(x_train[2, 0], cmap=\"gray\")\n",
        "axarr[1,0].imshow(x_train[3, 0], cmap=\"gray\")\n",
        "axarr[1,1].imshow(x_train[4, 0], cmap=\"gray\")\n",
        "np.vectorize(lambda ax:ax.axis('off'))(axarr);"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "baEsU4PGXsgS"
      },
      "source": [
        "Good! Let's now set up a few general setting before using torch..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ztZAPQNXZ4ll",
        "colab": {}
      },
      "source": [
        "# switch to False to use CPU\n",
        "use_cuda = True\n",
        "\n",
        "use_cuda = use_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\");\n",
        "torch.manual_seed(1);"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0Ek0mErIac6n"
      },
      "source": [
        "... and define our first conv-net! We will use 3 layers of convolutions and two fully connected layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ONMdybG4Be0z",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p9S6a-MlYAsu"
      },
      "source": [
        "Then we can write the *train* and *test* functions. Note that for simplicity here we are not using PyTorch [Data Loaders](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) but this is not recommended for efficiency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HGJJfXhJB-zk",
        "colab": {}
      },
      "source": [
        "def train(model, device, x_train, t_train, optimizer, epoch):\n",
        "    model.train()\n",
        "    \n",
        "    for start in range(0, len(t_train)-1, 256):\n",
        "      end = start + 256\n",
        "      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output = model(x)\n",
        "      loss = F.cross_entropy(output, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      #print(loss.item())\n",
        "    print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n",
        "\n",
        "def test(model, device, x_test, t_test):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for start in range(0, len(t_test)-1, 256):\n",
        "      end = start + 256\n",
        "      with torch.no_grad():\n",
        "        x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end]).long()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        output = model(x)\n",
        "        test_loss += F.cross_entropy(output, y).item() # sum up batch loss\n",
        "        pred = output.max(1, keepdim=True)[1] # get the index of the max logit\n",
        "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(t_test)\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(t_test),\n",
        "        100. * correct / len(t_test)))\n",
        "    return 100. * correct / len(t_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IxIISdDPaqb9"
      },
      "source": [
        "Then we are ready to instantiate our model and start the training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1cJURe0JCFh8",
        "colab": {}
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BlhVt8vylpUv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "8bf39d3f-0882-4778-d1c7-bd3cb706dba0"
      },
      "source": [
        "for epoch in range(1, 3):\n",
        "  train(model, device, x_train, t_train, optimizer, epoch)\n",
        "  test(model, device, x_test, t_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \tLoss: 0.754571\n",
            "Test set: Average loss: 0.0013, Accuracy: 9015/10000 (90%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.504929\n",
            "Test set: Average loss: 0.0007, Accuracy: 9433/10000 (94%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7qwh4T5Va86-"
      },
      "source": [
        "Wow! 94% accuracy in such a short time. \n",
        "\n",
        "**Questions to explore:**\n",
        "\n",
        "*   Can you find a better parametrization to improve the final accuracy?\n",
        "*   Can you change the network architecture to improve the final accuracy?\n",
        "*   Can you achieve the same performances with a smaller architecture?\n",
        "*   What's the difference in accuracy if you change convolutions with fully connected layers?\n",
        "\n",
        "Some tips here: http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2dn-5gOGq08g"
      },
      "source": [
        "But what if now we want we the same model being able to solve a new task we encounter over time like a permuted version of the same MNIST? Let's define our custom function to permute it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6Xq_4UvjgXPQ",
        "colab": {}
      },
      "source": [
        "def permute_mnist(mnist, seed):\n",
        "    \"\"\" Given the training set, permute pixels of each img the same way. \"\"\"\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    print(\"starting permutation...\")\n",
        "    h = w = 28\n",
        "    perm_inds = list(range(h*w))\n",
        "    np.random.shuffle(perm_inds)\n",
        "    # print(perm_inds)\n",
        "    perm_mnist = []\n",
        "    for set in mnist:\n",
        "        num_img = set.shape[0]\n",
        "        flat_set = set.reshape(num_img, w * h)\n",
        "        perm_mnist.append(flat_set[:, perm_inds].reshape(num_img, 1, w, h))\n",
        "    print(\"done.\")\n",
        "    return perm_mnist"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4xG5LFwLgkpu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "dbc667ed-56ee-4010-d305-0e7b857015e5"
      },
      "source": [
        "x_train2, x_test2 = permute_mnist([x_train, x_test], 0)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting permutation...\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LYBa_Gedh_do",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "ee4caff7-301d-432f-c725-994e861d2b9f"
      },
      "source": [
        "f, axarr = plt.subplots(1,2)\n",
        "axarr[0].imshow(x_train[1, 0], cmap=\"gray\")\n",
        "axarr[1].imshow(x_train2[2, 0], cmap=\"gray\")\n",
        "np.vectorize(lambda ax:ax.axis('off'))(axarr);"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAACmCAYAAAB5qlzZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALAElEQVR4nO3dWUhVfRfH8X2eymYLgkabwMpuzIpCoom6ayCiwSKUuimKIIQKA7MRymgODCNSNEmxiPIigjKKyKBouqqILpqkieYoG3wuXnh532et7bN3++x19tHv5/LXOnv/PZ4WB//DjjU3NzsAABt/JXoAANCW0HQBwBBNFwAM0XQBwBBNFwAM0XQBwFD7lv4xFouxngyham5ujiXivlH4bF+7dk1kEyZMCOVekydPVvMrV66Ecj+vMjIy1Pz+/fvGI4k/t88233QBwBBNFwAM0XQBwFCspW3AUfi7F1q3tvw3Xc2oUaPU/O7du4GuW1NTo+Y5OTkiW758uciOHDmivj4rK0tkd+7c8Tk6b/76S/+O+PDhQ5Glp6eHMgY/+JsuAEQATRcADNF0AcAQTRcADNF0AcAQqxeQUMmweiEtLU1kz549CzyGyspKkeXm5ga+rh/79u0TWX5+vufXl5WViWz+/Plqbffu3UX2+/dvtVZbqVBXV6fWzp49W2QfPnxQa6urq0W2YsUKtTYoVi8AQATQdAHAEE0XAAzRdAHAEBNpSKhkmEhrDZYtW6bm2kRYshkxYoTIHjx4EPi6mZmZIrt3757n1zORBgARQNMFAEM0XQAwRNMFAEM0XQAwxOoFA2PHjhXZ6tWr1dq8vDyRVVRUqLWHDh0S2a1bt3yOLrFYvRB/2tZatwPAgyotLRVZPLbVfvv2TWSdOnUKfF1LrF4AgAig6QKAIZouABii6QKAISbS4kh7MqrjOE59fb3IUlNTA99POzO0V69ega9riYk0G+/fv1fznj17Go/k/505c0bN58yZE8r9LM8wZiINACKApgsAhmi6AGCIpgsAhmi6AGCI1Qt/aPz48SI7deqUWtu/f3+Rub3vnz59EllTU5Naq61UmDhxolqrbQ92u64lVi94U1RUJLKtW7eGcq8BAwaI7Pnz54Gvm52dLbKuXbuqtRcvXhTZ/fv31dobN26IzG1FQmNjo8j69eun1gbF6gUAiACaLgAYoukCgCGaLgAYYiLtf3Tp0kXNx4wZI7Ljx4+LLC0tTX19LCb/nu72vmsTXrt27VJrq6urPd3LcRynsLBQZDt27FBrLbWFiTTtfFvHCe+MW0QDE2kAEAE0XQAwRNMFAEM0XQAwRNMFAEPtEz2AKNGebOo4jrN48WKzMWgrJbp166bWXr58WWRTp05VazMzMwONC968fftWZGGtUli7dq2a7969O5T7WSooKBDZzp07EzASb4qLiz3X8k0XAAzRdAHAEE0XAAzRdAHAUJudSBs7dqzIZs6cqda6ba39J21iy3Ecp66uTmRukx0vXrwQ2e3bt9Xad+/eiWzatGlqrdefAZLbNl6N5fvsNpE2ffp0kfXt21etXblypcjy8/NFlpOTo75+//79Ihs6dKhaqz3hV3s6r+OE94TeoCoqKtQ8Ly9PZOvXr1dr+aYLAIZougBgiKYLAIZougBgiKYLAIZa/SHmWVlZal5fXy+y1NRUz9c9d+6cyNy2C0+ZMkVkbttyjx49KrLXr197HtevX7/U/OvXr57G5Tj6QephSYZDzBcsWCCy2trauI4nbBkZGWq+ZcsWkbmtVNBoKztGjhyp1j548EBkZWVlau2yZcs8j8GPuXPniuz06dOh3ItDzAEgAmi6AGCIpgsAhmi6AGCoVU2kDR8+XGSbNm1SaxctWiSyN2/eqLWNjY0i2759u8hOnjz5b0MMndtEmvZ7rqmpUWuXLFkS1zG1JBkm0sKi/a7atWuXgJG0Hdpnu6qqKpR7MZEGABFA0wUAQzRdADBE0wUAQzRdADCUlIeYd+zYUc21g8FnzJih1n769Elk2kHEjuM4N2/eFFnnzp1bGmJSGDRoUKKHkLTcDjb38+RfP0+Z1laa+Nmui/8Ia6WCH3zTBQBDNF0AMETTBQBDNF0AMJSU24Czs7PV/OrVq56voT0x1e1pvsnEzzbghoYGtXbSpElxHVNL2vI24FevXomsd+/eCRhJcnA7e/fChQsii8KEGduAASACaLoAYIimCwCGaLoAYCgpd6Tt3btXzWMx+Xdrt8mx1jBppnHbEeW2gwqJw6SZP/F4WOWZM2dENmfOnMDX9YNvugBgiKYLAIZougBgiKYLAIZougBgKPKrF2bNmiWyrKwstVbb6nr27Nm4jynK3FYpaO/NnTt3wh4O4kT7vdbW1qq1nLPr7tq1ayIrKChQa7X3cfTo0YHHwDddADBE0wUAQzRdADBE0wUAQ5GfSNMeAJmSkqLWaueTag/0SzZuD+LcvHmz52vU19eLbMOGDX86JBjz88DLZNKhQwc1//HjR6DrLl26VM2Li4s9X2Pnzp0i07YRO46/rcSt8zcJABFF0wUAQzRdADBE0wUAQzRdADAU+dULfnz//l1kjY2NCRjJn9NWKhQWFqq169atE9mzZ8/U2j179ojs8+fPPkeHP+G2NVtbkfDlyxe1tmvXrp7vd/v2bZHFY/tqUE1NTSJzW4kUVHl5uedaPysS3FYpaE8Xd8M3XQAwRNMFAEM0XQAwRNMFAEOtaiItmc7OdTsTWJscczsfVZsAmDdvXrCBQUhNTRXZx48fPb/ezxZePxNmbsKYNBs4cKCaP3361PM1tEmzkpIStXbVqlWer6udkTthwgS1VjtXWnuKuF8XL170XMs3XQAwRNMFAEM0XQAwRNMFAEM0XQAwFNNm8/77j7GY+z8aWbhwochOnDih1mpbYAcPHhz3MfmVn58vso0bN6q1PXr0EFlVVZVam5eXF2xgEdDc3Bx86vgP+Pls9+zZU2Tv378PPAZte3BrPaw8yurq6tR89uzZga7r9tnmNwwAhmi6AGCIpgsAhmi6AGAo8tuAtYk+t8m/vn37iuzgwYNq7bFjx0T29u1btTY7O1tkubm5Ihs1apT6+rS0NJE9efJErT1//rzI3LZKIr5KS0vVfMWKFaHcL+ikWUFBgZprT7H149evXyJr165doGvGg9vEcUVFRaDruk2Y3bt3T2SZmZmB7uU4fNMFAFM0XQAwRNMFAEM0XQAwRNMFAEOR3wa8YMECkbltA/bj5cuXInM7mHrYsGGB7tXQ0CCyS5cuqbVFRUWB7pVskmEbsKampkbN3Q6ct6Qd5u/2VOywVmZotP9zffr0Mbt/PLiNV/vZ2AYMABFA0wUAQzRdADBE0wUAQ5GfSNO20NbW1qq148aN83xd7QmgLb0X/6RtGa6urlZr16xZ4/m6bU2UJtIePXqk1qanp4c+Hvy7Dx8+qLn2/6u8vFyttTzDmIk0AIgAmi4AGKLpAoAhmi4AGKLpAoChyK9e0PTr10/NtS2NhYWFaq2f1QsHDhwQ2eHDh0XmNvsNd1FavYDW7+fPnyJr3z6cZzmwegEAIoCmCwCGaLoAYIimCwCGknIiDa0HE2nxp211raqqUmuXLFkisrC2xT5+/FhkQ4YMUWvDGoMlJtIAIAJougBgiKYLAIZougBgiKYLAIZYvYCEYvVC/GlPKrZ8SrG2esJxwluRUFlZKbLc3NxQ7uUHqxcAIAJougBgiKYLAIZougBgiIk0JFSiJtKKiorEZ3vbtm1qreUTZN1kZ2eL7Pr164GvG4WfzauSkhI1X7VqldkYmpqa1DwlJUVkTKQBQATQdAHAEE0XAAzRdAHAEE0XAAyxegEJxTZgb1i9kHxYvQAAEUDTBQBDNF0AMETTBQBDLU6kAQDii2+6AGCIpgsAhmi6AGCIpgsAhmi6AGCIpgsAhv4GzmwpIfcmmzcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "46wHcbNAchH-"
      },
      "source": [
        "Amazing. Now let's see how our pre-trained model is working on both the original and the permuted MNIST dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sxusb8s3itli",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "fff70949-fd53-4934-e8fd-09df2351c943"
      },
      "source": [
        "print(\"Testing on the first task:\")\n",
        "test(model, device, x_test, t_test)\n",
        "\n",
        "print(\"Testing on the second task:\")\n",
        "test(model, device, x_test2, t_test);"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing on the first task:\n",
            "Test set: Average loss: 0.0007, Accuracy: 9433/10000 (94%)\n",
            "\n",
            "Testing on the second task:\n",
            "Test set: Average loss: 0.0108, Accuracy: 1023/10000 (10%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0pHMg4G_dHFY"
      },
      "source": [
        "Mmmh... that's pretty bad, our model cannot generalize to this apparently very different new task! Well, we can just finetune our model using the new permuted training set!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J5PtR8Gqib00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "01f82726-09e1-4ca3-c37f-578bf4f41e92"
      },
      "source": [
        "for epoch in range(1, 3):\n",
        "  train(model, device, x_train2, t_train, optimizer, epoch)\n",
        "  test(model, device, x_test2, t_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \tLoss: 1.491783\n",
            "Test set: Average loss: 0.0032, Accuracy: 7366/10000 (74%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 1.182255\n",
            "Test set: Average loss: 0.0022, Accuracy: 8254/10000 (83%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ML7Evzb9jPAZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "28c2d43c-f9ab-4de7-de9e-f4948bf174fa"
      },
      "source": [
        "print(\"Testing on the first task:\")\n",
        "test(model, device, x_test, t_test)\n",
        "\n",
        "print(\"Testing on the second task:\")\n",
        "test(model, device, x_test2, t_test);"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing on the first task:\n",
            "Test set: Average loss: 0.0207, Accuracy: 2334/10000 (23%)\n",
            "\n",
            "Testing on the second task:\n",
            "Test set: Average loss: 0.0022, Accuracy: 8254/10000 (83%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0UZ6FBuHdm7N"
      },
      "source": [
        "This is very annoying! Now we are not able to solve the original MNSIT task anymore! :-( This is the phenomenon known in literature as **Catastrophic Forgetting**! In the following section we well compare three different strategies for learning continually (and trying to not forget!)\n",
        "\n",
        "**Questions to explore:**\n",
        "\n",
        "*   When the permuted MNIST benchmark has been firstly introduced? \n",
        "*   Can simple Dropout and Regularization techniques reduce forgetting?\n",
        "*   In the permuted MNIST task, do convolutions still help increasing the accuracy?\n",
        "\n",
        "Some tips here: https://papers.nips.cc/paper/5059-compete-to-compute"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9rUgLpUakTy6"
      },
      "source": [
        "## CL Strategies\n",
        "\n",
        "Let us now focus on some strategies for reducing catastrofic forgetting, one of the principal problems when learning continuously. in this section we will take a look at three different strategies:\n",
        "\n",
        "1.   Naive\n",
        "2.   Rehearsal\n",
        "3.   Elastic Weight Consolidation (EWC)\n",
        "\n",
        "and run it on a 3-tasks Permuted MNIST. Finally we will plot our results for comparison. For a more comprehensive overview on recent CL strategies for deep learning take a look at the recent paper \"[Continuous Learning in Single-Incremental-Task Scenarios](https://arxiv.org/abs/1806.08568)\".\n",
        "\n",
        "Let's start by defining our 3 tasks with the function we have already introduced before:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yu0T_V24joGY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "f93802ee-10b9-4bd4-8b2c-ceb294ad898b"
      },
      "source": [
        "# task 1\n",
        "task_1 = [(x_train, t_train), (x_test, t_test)]\n",
        "\n",
        "# task 2\n",
        "x_train2, x_test2 = permute_mnist([x_train, x_test], 1)\n",
        "task_2 = [(x_train2, t_train), (x_test2, t_test)]\n",
        "\n",
        "# task 3\n",
        "x_train3, x_test3 = permute_mnist([x_train, x_test], 2)\n",
        "task_3 = [(x_train3, t_train), (x_test3, t_test)]\n",
        "\n",
        "# task list\n",
        "tasks = [task_1, task_2, task_3]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting permutation...\n",
            "done.\n",
            "starting permutation...\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yUNaukXyiJni"
      },
      "source": [
        "### Naive Strategy\n",
        "\n",
        "The  *Naive* strategy, is the simple idea of continuing the back-prop process on the new batches/tasks. This is very simple, but at the same time very prone to forgetting as we have witnessed before. Let's how it works on three tasks:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gzFEA5F8pI_O",
        "colab": {}
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dLU6KdIbnLMN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "outputId": "ab71315f-1c40-45b3-d115-b5b21a2ac3e9"
      },
      "source": [
        "naive_accs = []\n",
        "\n",
        "for id, task in enumerate(tasks):\n",
        "  avg_acc = 0\n",
        "  print(\"Training on task: \", id)\n",
        "  \n",
        "  (x_train, t_train), _ = task\n",
        "  \n",
        "  for epoch in range(1, 2):\n",
        "    train(model, device, x_train, t_train, optimizer, epoch)\n",
        "    \n",
        "  for id_test, task in enumerate(tasks):\n",
        "    print(\"Testing on task: \", id_test)\n",
        "    _, (x_test, t_test) = task\n",
        "    acc = test(model, device, x_test, t_test)\n",
        "    avg_acc = avg_acc + acc \n",
        "  \n",
        "  naive_accs.append(avg_acc / 3)\n",
        "  print(\"Avg acc: \", avg_acc / 3)\n",
        "  "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.671781\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0013, Accuracy: 9018/10000 (90%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0113, Accuracy: 627/10000 (6%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0101, Accuracy: 1264/10000 (13%)\n",
            "\n",
            "Avg acc:  36.36333333333334\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.718019\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0128, Accuracy: 2014/10000 (20%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0051, Accuracy: 6360/10000 (64%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0100, Accuracy: 1245/10000 (12%)\n",
            "\n",
            "Avg acc:  32.06333333333334\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 1.629070\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0249, Accuracy: 1685/10000 (17%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0075, Accuracy: 3382/10000 (34%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0036, Accuracy: 7264/10000 (73%)\n",
            "\n",
            "Avg acc:  41.10333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ANJfdFD3s0oT"
      },
      "source": [
        "**Questions to explore:**\n",
        "\n",
        "*   Does the order of the tasks effect the final results? \n",
        "\n",
        "Some tips here: http://proceedings.mlr.press/v78/lomonaco17a/lomonaco17a.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lCK0EYT-pJa8"
      },
      "source": [
        "### Rehearsal Strategy\n",
        "\n",
        "Another simple CL idea is to carry on *all* or *part* of the previously encountered examples (of the previous tasks), shuffling them with the data of the current task. Using *all* the past data is near to the optimal performance we can desire at the end of the task sequence but at the expense of much bigger memory usage.\n",
        "\n",
        "Let's start by defining a function to shuffle our data:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FdWpT2jhfu3o",
        "colab": {}
      },
      "source": [
        "def shuffle_in_unison(dataset, seed, in_place=False):\n",
        "    \"\"\" Shuffle two (or more) list in unison. \"\"\"\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    rng_state = np.random.get_state()\n",
        "    new_dataset = []\n",
        "    for x in dataset:\n",
        "        if in_place:\n",
        "            np.random.shuffle(x)\n",
        "        else:\n",
        "            new_dataset.append(np.random.permutation(x))\n",
        "        np.random.set_state(rng_state)\n",
        "\n",
        "    if not in_place:\n",
        "        return new_dataset"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "94hg1UrtqFmT"
      },
      "source": [
        "Now we can reset the model and optimizer and run our training over the tasks sequence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "62TY0Ajgbsgk",
        "colab": {}
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y_No-qvDbuZi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "outputId": "01ffced1-acf4-49b4-f1b4-3c724d420b91"
      },
      "source": [
        "rehe_accs = []\n",
        "for id, task in enumerate(tasks):\n",
        "  avg_acc = 0\n",
        "  print(\"Training on task: \", id)\n",
        "  \n",
        "  (x_train, t_train), _ = task\n",
        "  \n",
        "  # for previous task\n",
        "  for i in range(id):\n",
        "    (past_x_train, past_t_train), _ = tasks[i]\n",
        "    x_train = np.concatenate((x_train, past_x_train))\n",
        "    t_train = np.concatenate((t_train, past_t_train))\n",
        "  \n",
        "  x_train, t_train = shuffle_in_unison([x_train, t_train], 0)\n",
        "  \n",
        "  for epoch in range(1, 2):\n",
        "    train(model, device, x_train, t_train, optimizer, epoch)\n",
        "    \n",
        "  for id_test, task in enumerate(tasks):\n",
        "    print(\"Testing on task: \", id_test)\n",
        "    _, (x_test, t_test) = task\n",
        "    acc = test(model, device, x_test, t_test)\n",
        "    avg_acc = avg_acc + acc\n",
        "   \n",
        "  print(\"Avg acc: \", avg_acc / 3)\n",
        "  rehe_accs.append(avg_acc/3)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.585555\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0014, Accuracy: 9052/10000 (91%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0113, Accuracy: 581/10000 (6%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0101, Accuracy: 1035/10000 (10%)\n",
            "\n",
            "Avg acc:  35.559999999999995\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 0.847921\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0008, Accuracy: 9417/10000 (94%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0037, Accuracy: 7465/10000 (75%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0102, Accuracy: 1101/10000 (11%)\n",
            "\n",
            "Avg acc:  59.94333333333333\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 0.544804\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0007, Accuracy: 9507/10000 (95%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0021, Accuracy: 8507/10000 (85%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0024, Accuracy: 8260/10000 (83%)\n",
            "\n",
            "Avg acc:  87.58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jCna5k0DtN-X"
      },
      "source": [
        "**Questions to explore:**\n",
        "\n",
        "*   Can you find a way to reduce the number of examples of the previous tasks to maintain in memory? \n",
        "*   Can you find a good trade-off between memory overhead and final accuracy?\n",
        "*   Why is shuffling needed here?\n",
        "\n",
        "Some tips here: https://arxiv.org/abs/1809.05922"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AqofPHt01Zog"
      },
      "source": [
        "### Elastic Weights Consolidation (EWC) Strategy\n",
        "\n",
        "Elastic Weights Consolidation (EWC) is a common CL strategy firstly proposed in the paper: \"[Overcoming catastrophic forgetting in neural networks](https://arxiv.org/abs/1612.00796)\" for deep neural networks.\n",
        "\n",
        "It is based on the computation of the importance of each weight (fisher information) and a squared regularization loss, penalizing changes in the most important wheights for the previous tasks.\n",
        "\n",
        "It has the great advantage of **not using any** of the previous tasks data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e9iry5W56xtO",
        "colab": {}
      },
      "source": [
        "fisher_dict = {}\n",
        "optpar_dict = {}\n",
        "ewc_lambda = 0.4"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0ZlyqcICEps_",
        "colab": {}
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Clm_QFF12mO9"
      },
      "source": [
        "Now we need to define an additional function to compute the fisher information for each weight at the end of each task:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iEmBNkaO1Ykq",
        "colab": {}
      },
      "source": [
        "def on_task_update(task_id, x_mem, t_mem):\n",
        "\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  # accumulating gradients\n",
        "  for start in range(0, len(t_mem)-1, 256):\n",
        "      end = start + 256\n",
        "      x, y = torch.from_numpy(x_mem[start:end]), torch.from_numpy(t_mem[start:end]).long()\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      output = model(x)\n",
        "      loss = F.cross_entropy(output, y)\n",
        "      loss.backward()\n",
        "\n",
        "  fisher_dict[task_id] = {}\n",
        "  optpar_dict[task_id] = {}\n",
        "\n",
        "  # gradients accumulated can be used to calculate fisher\n",
        "  for name, param in model.named_parameters():\n",
        "    \n",
        "    optpar_dict[task_id][name] = param.data.clone()\n",
        "    fisher_dict[task_id][name] = param.grad.data.clone().pow(2)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2hGp0Qsf2wa-"
      },
      "source": [
        "We need also to modify our *train* function to add the new regularization loss:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IorTFus1Gs5H",
        "colab": {}
      },
      "source": [
        "def train_ewc(model, device, task_id, x_train, t_train, optimizer, epoch):\n",
        "    model.train()\n",
        "\n",
        "    for start in range(0, len(t_train)-1, 256):\n",
        "      end = start + 256\n",
        "      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output = model(x)\n",
        "      loss = F.cross_entropy(output, y)\n",
        "      \n",
        "      ### magic here! :-)\n",
        "      for task in range(task_id):\n",
        "        for name, param in model.named_parameters():\n",
        "          fisher = fisher_dict[task][name]\n",
        "          optpar = optpar_dict[task][name]\n",
        "          loss += (fisher * (optpar - param).pow(2)).sum() * ewc_lambda\n",
        "      \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      #print(loss.item())\n",
        "    print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u754qi423EEc"
      },
      "source": [
        "Finally we can run the train over the three tasks sequence of th *Permuted MNIST*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IkUCo4C6-QpT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "outputId": "33b5e194-5a1d-4fe0-a3ce-e42f3c247364"
      },
      "source": [
        "ewc_accs = []\n",
        "for id, task in enumerate(tasks):\n",
        "  avg_acc = 0\n",
        "  print(\"Training on task: \", id)\n",
        "  \n",
        "  (x_train, t_train), _ = task\n",
        "  \n",
        "  for epoch in range(1, 3):\n",
        "    train_ewc(model, device, id, x_train, t_train, optimizer, epoch)\n",
        "  on_task_update(id, x_train, t_train)\n",
        "    \n",
        "  for id_test, task in enumerate(tasks):\n",
        "    print(\"Testing on task: \", id_test)\n",
        "    _, (x_test, t_test) = task\n",
        "    acc = test(model, device, x_test, t_test)\n",
        "    avg_acc = avg_acc + acc\n",
        "   \n",
        "  print(\"Avg acc: \", avg_acc / 3)\n",
        "  ewc_accs.append(avg_acc / 3)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.827583\n",
            "Train Epoch: 2 \tLoss: 0.661672\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0007, Accuracy: 9455/10000 (95%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0116, Accuracy: 641/10000 (6%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0097, Accuracy: 1169/10000 (12%)\n",
            "\n",
            "Avg acc:  37.55\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 2.006719\n",
            "Train Epoch: 2 \tLoss: 1.604596\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0061, Accuracy: 5871/10000 (59%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0033, Accuracy: 7803/10000 (78%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0113, Accuracy: 1108/10000 (11%)\n",
            "\n",
            "Avg acc:  49.27333333333334\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 2.046566\n",
            "Train Epoch: 2 \tLoss: 1.975376\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0071, Accuracy: 5995/10000 (60%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0072, Accuracy: 3948/10000 (39%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0041, Accuracy: 7217/10000 (72%)\n",
            "\n",
            "Avg acc:  57.20000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nx4bR5K1uIwU"
      },
      "source": [
        "**Questions to explore:**\n",
        "\n",
        "*   How much the `ewc_lambda` parameter effect the final results? \n",
        "*   Can you find a better parametrization to improve stability?\n",
        "*   Can you find the memory overhead introduced by EWC with respect to the Naive approach?\n",
        "\n",
        "Some tips here: https://arxiv.org/pdf/1805.06370.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o3SM7U5fwTqV"
      },
      "source": [
        "### Plot Results\n",
        "\n",
        "To conclude, let's summerize our results in a nice plot! :-)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sIQEVVpDwPP5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "f9c7fc2b-e727-447c-d4f6-e9fa6a778efb"
      },
      "source": [
        "plt.plot([1, 2, 3], naive_accs, '-o', label=\"Naive\")\n",
        "plt.plot([1, 2, 3], rehe_accs, '-o', label=\"Rehearsal\")\n",
        "plt.plot([1, 2, 3], ewc_accs, '-o', label=\"EWC\")\n",
        "plt.xlabel('Tasks Encountered', fontsize=14)\n",
        "plt.ylabel('Average Accuracy', fontsize=14)\n",
        "plt.title('CL Strategies Comparison on MNSIT', fontsize=14);\n",
        "plt.xticks([1, 2, 3])\n",
        "plt.legend(prop={'size': 16});"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9x1D3O7iunxS"
      },
      "source": [
        "**Questions to explore:**\n",
        "\n",
        "*   What's the difference in terms of memory utilization among the three methods? \n",
        "*   Can you plot a similar graph highlighting the memory increase over time?\n",
        "\n",
        "Some tips here: https://stackoverflow.com/questions/449560/how-do-i-determine-the-size-of-an-object-in-python/30316760"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OS9gHzZM7HQr"
      },
      "source": [
        "**Copyright (c) 2018. ContinualAI. AIforPeople 2020. All rights reserved.**\n",
        "\n",
        "See the accompanying LICENSE file in the GitHub repository for terms. \n",
        "\n",
        "*Date: 08-08-2020*                                       \n",
        "\n",
        "Author: Vincenzo Lomonaco                                                    \n",
        "E-mail: contact@aiforpeople.org                 \n",
        "Website: www.aiforpeople.org                                             "
      ]
    }
  ]
}